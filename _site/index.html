<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Home - Thomas Graves</title>
  <!-- Tailwind and fonts -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.7.77/Tone.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  <style>
    :root {
      --color-secondary: #334155;
      --color-border: #27272A;
      --color-bg-card: #18181B;
    }
    body {
      font-family: 'Inter', sans-serif;
      background-color: #0A0A0A;
      color: #E0E0E0;
    }
    #bg-canvas {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: -10;
    }
    .interactive-rainbow {
      position: relative;
      z-index: 1;
      overflow: hidden;
      border: 3px solid transparent;
      color: white;
    }
    .interactive-rainbow::before {
      content: '';
      position: absolute;
      z-index: -2;
      left: var(--x, 50%);
      top: var(--y, 50%);
      width: 250%;
      padding-bottom: 250%;
      transform: translate(-50%, -50%);
      background: conic-gradient(
        from var(--angle, 0deg),
        #ff2a2a, #ff8000, #ffff00, #40ff00,
        #00ffff, #0080ff, #8000ff, #ff00ff, #ff2a2a
      );
      opacity: 0;
      transition: opacity 0.2s ease;
    }
    .interactive-rainbow::after {
      content: '';
      position: absolute;
      z-index: -1;
      inset: 3px;
      background: var(--color-bg-card);
      border-radius: inherit;
    }
    .interactive-rainbow:hover::before {
      opacity: 0.15;
    }
    .nav-link.active.interactive-rainbow::before {
      opacity: 0.25;
    }

    /* Loading Animation Styles */
    #loading-overlay {
      transition: opacity 0.3s ease-in-out;
    }
    #explosion-background.exploding {
      opacity: 1;
      animation: color-explosion 0.8s forwards;
    }

    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }

    @keyframes color-explosion {
      0% { background: radial-gradient(circle, #ff2a2a 0%, transparent 10%); }
      20% { background: radial-gradient(circle, #ffff00 20%, #8000ff 40%, transparent 60%); }
      40% { background: radial-gradient(circle, #00ffff 40%, #ff8000 60%, transparent 80%); }
      60% { background: radial-gradient(circle, #8000ff 60%, #00ffff 80%, transparent 100%); }
      80% { background: radial-gradient(circle, #ff2a2a 80%, #ffff00 100%, transparent 120%); }
      100% { background: transparent; opacity: 0; }
    }
  </style>
</head>
<body class="antialiased">
  <canvas id="bg-canvas"></canvas>

  <div id="explosion-background" class="fixed inset-0 z-[99] pointer-events-none opacity-0"></div>

  <div id="loading-overlay" class="fixed inset-0 z-[100] bg-black/70 flex-col items-center justify-center text-center hidden opacity-0">
    <div class="flex flex-col items-center gap-4">
      <div class="text-white text-2xl font-bold tracking-[0.2em] uppercase animate-[pulse_1.5s_infinite_ease-in-out]">Loading...</div>
      <div class="w-[300px] h-2.5 bg-black/50 rounded-full overflow-hidden">
        <div id="loading-bar-progress" class="h-full w-0 rounded-full transition-[width] duration-[2000ms] linear" style="background: linear-gradient(90deg, #ff2a2a, #ff8000, #ffff00, #40ff00, #00ffff, #0080ff, #8000ff, #ff00ff); background-size: 200% 200%;"></div>
      </div>
    </div>
  </div>

  <div id="no-vr-modal" class="fixed inset-0 z-[100] bg-black/70 flex items-center justify-center text-center hidden">
    <div class="bg-[var(--color-bg-card)] border border-[var(--color-border)] rounded-xl p-8 max-w-sm mx-4">
      <h3 class="text-2xl font-bold text-white mb-4 uppercase tracking-wide">No VR Detected</h3>
      <p class="text-gray-400 mb-6">This experience is designed for WebXR-compatible VR or AR headsets. Please try again on a supported device.</p>
      <button id="close-no-vr-modal" class="sound-interactive interactive-rainbow px-6 py-3 font-semibold uppercase tracking-wider rounded-lg">Close</button>
    </div>
  </div>

  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 relative z-10">
    <!-- Header -->
    <header class="py-6 sticky top-0 z-50 bg-[#0A0A0A]">
      <nav class="flex justify-between items-center">
        <div class="flex items-center gap-4">
          <a href="/" id="home-link" class="sound-interactive text-2xl font-bold tracking-tighter text-white hover:text-gray-300">Thomas Graves</a>
          <button id="sound-toggle" title="Toggle Sound" class="text-gray-500 hover:text-white transition-colors focus:outline-none">
            <svg id="sound-off-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
              <path stroke-linecap="round" stroke-linejoin="round" d="M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" clip-rule="evenodd" />
              <path stroke-linecap="round" stroke-linejoin="round" d="M17 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2" />
            </svg>
            <svg id="sound-on-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 hidden" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
              <path stroke-linecap="round" stroke-linejoin="round" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
            </svg>
          </button>
        </div>
        <div class="hidden md:flex items-center space-x-2">
          <a href="/work/" class="sound-interactive interactive-rainbow uppercase text-sm tracking-wider px-3 py-2 rounded-md cursor-pointer transition-colors hover:text-white">Work</a>
          <a href="/about/" class="sound-interactive interactive-rainbow uppercase text-sm tracking-wider px-3 py-2 rounded-md cursor-pointer transition-colors hover:text-white">About</a>
          <a href="/blog/" class="sound-interactive interactive-rainbow uppercase text-sm tracking-wider px-3 py-2 rounded-md cursor-pointer transition-colors hover:text-white">Blog</a>
        </div>
        <a href="mailto:hello@thomasgraves.art" class="sound-interactive hidden md:inline-block interactive-rainbow px-6 py-3 font-semibold uppercase tracking-wider rounded-lg">Contact</a>

        <div class="md:hidden">
          <button id="mobile-menu-button" class="sound-interactive text-white focus:outline-none">
            <svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7" />
            </svg>
          </button>
        </div>
      </nav>
      
      <div id="mobile-menu" class="hidden md:hidden flex-col text-center space-y-2 absolute top-full left-0 right-0 bg-[#0A0A0A] py-4 border-b border-[var(--color-border)] z-50">
        <a href="/work/" class="sound-interactive interactive-rainbow block py-2">Work</a>
        <a href="/about/" class="sound-interactive interactive-rainbow block py-2">About</a>
        <a href="/blog/" class="sound-interactive interactive-rainbow block py-2">Blog</a>
        <a href="mailto:hello@thomasgraves.art" class="sound-interactive interactive-rainbow w-1/2 mx-auto mt-4 px-6 py-3 font-semibold uppercase tracking-wider rounded-lg">Contact</a>
      </div>
    </header>
    <main id="main-content" class="transition-opacity duration-300 ease-in-out">
      
      <div id="main-content-container" style="opacity: 1; display: block;">
        <section id="main-content-hero" class="text-center py-20 sm:py-28">
          <section class="text-center py-20 sm:py-28">
  <h1 class="text-4xl sm:text-6xl font-extrabold tracking-tight text-white leading-tight uppercase" style="letter-spacing: 0.05em;">A Mixed Reality Musician</h1>
  <p class="max-w-3xl mx-auto mt-6 text-lg text-gray-400">I build projects that explore the frontiers of music, interaction, and perception.</p>
  <button id="reality-engine-btn" class="sound-interactive interactive-rainbow mt-8 px-8 py-4 text-lg font-bold uppercase tracking-wider rounded-lg transition-all duration-300 hover:scale-105">
    Enter the Graves Reality Engine
  </button>
</section>
        </section>
      </div>
      
    </main>
    
    <!-- Loading overlay for transitions -->
    <div id="page-transition-overlay" class="fixed inset-0 bg-[#0A0A0A] z-50 opacity-0 pointer-events-none transition-opacity duration-300"></div>
    <footer id="page-footer" class="text-center py-12 mt-16 border-t border-[var(--color-border)]">
      <p class="text-gray-500">&copy; 2025 Thomas Graves. All Rights Reserved.</p>
    </footer>
  </div>

  <script>
    // AUDIO CONFIGURATION - Edit these settings to customize sounds
    const AUDIO_CONFIG = {
      masterVolume: -10,
      synths: {
        hover: { type: 'fatsine2', volume: -24, envelope: { attack: 0.1, decay: 0.2, sustain: 0.3, release: 0.8 } },
        click: { type: 'fatsine4', volume: -10, envelope: { attack: 0.01, decay: 0.1, sustain: 0, release: 0.3 } },
        highClick: { type: 'sine', volume: -14, envelope: { attack: 0.01, decay: 0.05, sustain: 0, release: 0.2 } },
        pad: { type: 'AMSynth', volume: -20, envelope: { attack: 2.0, decay: 1.0, sustain: 0.8, release: 4.0 } },
        melody: { type: 'triangle8', volume: -18, envelope: { attack: 0.1, decay: 0.2, sustain: 0.5, release: 1.0 } }
      },
      effects: { reverb: { roomSize: 3, wetness: 0.4 }, filter: { frequency: "2m" } }
    };

    // Musical Data from Original
    const NOTE_COLORS = {
      'C': 0xff2a2a, 'C#': 0xff8000, 'D': 0xffff00, 'D#': 0x40ff00,
      'E': 0x00ffff, 'F': 0x0080ff, 'F#': 0x8000ff, 'G': 0xff00ff,
      'G#': 0xff2a2a, 'A': 0xff8000, 'A#': 0xffff00, 'B': 0x40ff00
    };
    const CHROMATIC_SCALE = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const TONE_ROWS = [
      ['G4', 'F#4', 'A4', 'C#5', 'D#4', 'B4', 'C4', 'E4', 'F4', 'G#4', 'A#4', 'D4'],
      ['A4', 'G#4', 'B4', 'D#5', 'F#4', 'C#4', 'D4', 'F4', 'G4', 'A#4', 'C5', 'E4'],
      ['C4', 'D4', 'B3', 'E4', 'F#4', 'G#4', 'A#4', 'C#5', 'D#5', 'F5', 'G5', 'A5'],
      ['F#4', 'E4', 'G4', 'D#4', 'C#4', 'A#3', 'A3', 'C4', 'D4', 'F4', 'G#4', 'B4'],
      ['D4', 'E4', 'C#4', 'F#4', 'G#4', 'A#4', 'B4', 'D#5', 'F5', 'G5', 'A5', 'C5']
    ];
    const WHOLE_TONE_SCALES = [
      ['C', 'D', 'E', 'F#', 'G#', 'A#'],
      ['C#', 'D#', 'F', 'G', 'A', 'B']
    ];

    // App State
    const AppState = {
      isSoundEnabled: false,
      activePage: 'hero',
      currentToneRowIndex: 0,
      isTransitioning: false,
      pageToShowAfterTransition: null,
      transitionTimeoutId: null,
      visualQueue: [],
      wholeToneStartIndex: 0,
      wholeToneDirection: 1,
    };

    // Function to wait for libraries to load
    function waitForLibraries() {
      return new Promise((resolve) => {
        function checkLibraries() {
          if (typeof THREE !== 'undefined' && typeof Tone !== 'undefined') {
            console.log('✅ All libraries loaded');
            resolve();
          } else {
            console.log('⏳ Waiting for libraries... THREE:', typeof THREE !== 'undefined', 'Tone:', typeof Tone !== 'undefined');
            setTimeout(checkLibraries, 100);
          }
        }
        checkLibraries();
      });
    }

    // 3D Background System - WILL BE CREATED AFTER LIBRARIES LOAD
    let ThreeDBackground = null;

    document.addEventListener('DOMContentLoaded', async () => {
      console.log('📄 DOM Content Loaded');
      
      // Wait for external libraries to load
      await waitForLibraries();
      
      console.log('🔧 Creating 3D Background system...');
      
      // NOW create the ThreeDBackground object with THREE.js available
      ThreeDBackground = {
        scene: null, camera: null, renderer: null, worldGrid: new Map(),
        cameraTargetPosition: new THREE.Vector3(0, 0, 2),
        mouse: { x: 0, y: 0 },
        baseSphereColor: new THREE.Color(0x222222),
        sphereGeometry: null, sphereMaterial: null,
        CHUNK_SIZE: 12, VIEW_DISTANCE: 3,
        
        // Enhanced Camera Movement System
        cameraMovement: {
          enabled: true,
          velocity: { x: 0, y: 0, z: 0 },
          targetPosition: { x: 0, y: 0, z: 2 },
          currentTarget: { x: 0, y: 0, z: 2 },
          lastChangeTime: 0,
          changeInterval: 12000, // Change direction every 12 seconds
          constraints: {
            x: { min: -15, max: 15 },
            y: { min: -10, max: 10 },
            z: { min: 1, max: 8 }
          },
          dampening: 0.92,
          acceleration: 0.0015,
          maxSpeed: 0.06,
          smoothness: 0.02
        },

        init() {
        console.log('🌟 Initializing ThreeDBackground...');
        
        const canvas = document.getElementById('bg-canvas');
        if (!canvas) {
          console.error('❌ Canvas not available for ThreeJS initialization');
          return;
        }
        
        try {
          this.scene = new THREE.Scene();
          this.camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
          this.renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true });
          this.renderer.setSize(window.innerWidth, window.innerHeight);
          console.log('🖥️ Renderer created - canvas size:', canvas.width, 'x', canvas.height, 'window size:', window.innerWidth, 'x', window.innerHeight);
          this.scene.fog = new THREE.Fog(0x0A0A0A, 20, 80);
          this.sphereGeometry = new THREE.SphereGeometry(0.15, 16, 16);
          this.sphereMaterial = new THREE.MeshBasicMaterial({ color: this.baseSphereColor });
          this.camera.position.z = 2;
          this.cameraTargetPosition.copy(this.camera.position);
          
          // Initialize camera movement system
          this.cameraMovement.currentTarget.x = this.camera.position.x;
          this.cameraMovement.currentTarget.y = this.camera.position.y;
          this.cameraMovement.currentTarget.z = this.camera.position.z;
          this.cameraMovement.targetPosition.x = this.camera.position.x;
          this.cameraMovement.targetPosition.y = this.camera.position.y;
          this.cameraMovement.targetPosition.z = this.camera.position.z;
          this.cameraMovement.lastChangeTime = Date.now();
          console.log('🎯 Camera movement system initialized');
          this.updateWorldGrid(true);
          console.log('✅ ThreeDBackground initialized, starting animation...');
          
          // Force first render and start animation loop
          this.renderer.render(this.scene, this.camera);
          this.animate();
          
          window.addEventListener('resize', () => this.onWindowResize());
          document.addEventListener('mousemove', (e) => this.onMouseMove(e));
          
          console.log('🎬 Animation loop started, spheres should be visible');
        } catch (error) {
          console.error('❌ ThreeDBackground initialization failed:', error);
        }
      },

      onWindowResize() {
        this.camera.aspect = window.innerWidth / window.innerHeight;
        this.camera.updateProjectionMatrix();
        this.renderer.setSize(window.innerWidth, window.innerHeight);
      },

      onMouseMove(event) {
        this.mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
      },

      // Enhanced Camera Movement Methods
      generateRandomTarget() {
        const movement = this.cameraMovement;
        const constraints = movement.constraints;
        
        // Generate new random target within constraints
        movement.targetPosition.x = constraints.x.min + Math.random() * (constraints.x.max - constraints.x.min);
        movement.targetPosition.y = constraints.y.min + Math.random() * (constraints.y.max - constraints.y.min);
        movement.targetPosition.z = constraints.z.min + Math.random() * (constraints.z.max - constraints.z.min);
        
        console.log('🎯 New camera target:', movement.targetPosition);
      },

      updateCameraMovement() {
        if (!this.cameraMovement.enabled) return;
        
        const movement = this.cameraMovement;
        const now = Date.now();
        
        // Check if it's time to change target
        if (now - movement.lastChangeTime > movement.changeInterval) {
          this.generateRandomTarget();
          movement.lastChangeTime = now;
        }
        
        // Calculate force towards target
        const forceX = (movement.targetPosition.x - movement.currentTarget.x) * movement.acceleration;
        const forceY = (movement.targetPosition.y - movement.currentTarget.y) * movement.acceleration;
        const forceZ = (movement.targetPosition.z - movement.currentTarget.z) * movement.acceleration;
        
        // Update velocity with forces
        movement.velocity.x += forceX;
        movement.velocity.y += forceY;
        movement.velocity.z += forceZ;
        
        // Apply dampening
        movement.velocity.x *= movement.dampening;
        movement.velocity.y *= movement.dampening;
        movement.velocity.z *= movement.dampening;
        
        // Constrain velocity to max speed
        const speed = Math.sqrt(movement.velocity.x ** 2 + movement.velocity.y ** 2 + movement.velocity.z ** 2);
        if (speed > movement.maxSpeed) {
          const scale = movement.maxSpeed / speed;
          movement.velocity.x *= scale;
          movement.velocity.y *= scale;
          movement.velocity.z *= scale;
        }
        
        // Update current target position
        movement.currentTarget.x += movement.velocity.x;
        movement.currentTarget.y += movement.velocity.y;
        movement.currentTarget.z += movement.velocity.z;
        
        // Apply mouse parallax as secondary influence
        const parallaxInput = this.mouse.x;
        const parallaxStrength = 0.3;
        const parallaxX = parallaxInput * parallaxStrength;
        
        // Smooth interpolation to final camera position
        const finalX = movement.currentTarget.x + parallaxX;
        const finalY = movement.currentTarget.y;
        const finalZ = movement.currentTarget.z;
        
        this.camera.position.lerp(
          new THREE.Vector3(finalX, finalY, finalZ), 
          movement.smoothness
        );
      },

      generateChunk(chunkX, chunkY, chunkZ) {
        const key = `${chunkX},${chunkY},${chunkZ}`;
        if (this.worldGrid.has(key)) {
          console.log('🔄 Chunk already exists:', key);
          return;
        }
        
        console.log('🎲 Generating chunk:', key, 'at offset:', chunkX * this.CHUNK_SIZE, chunkY * this.CHUNK_SIZE, chunkZ * this.CHUNK_SIZE);
        
        const chunkSpheres = [];
        const offset = { x: chunkX * this.CHUNK_SIZE, y: chunkY * this.CHUNK_SIZE, z: chunkZ * this.CHUNK_SIZE };
        const octave = (chunkX % 8 + 8) % 8 + 2;
        for (let i = 0; i < 3; i++) {
          const sphere = new THREE.Mesh(this.sphereGeometry, this.sphereMaterial.clone());
          const noteIndex = Math.floor(Math.random() * 12);
          sphere.position.set(
            offset.x + (Math.random() - 0.5) * this.CHUNK_SIZE,
            offset.y + (Math.random() - 0.5) * this.CHUNK_SIZE,
            offset.z + (Math.random() - 0.5) * this.CHUNK_SIZE
          );
          sphere.userData = {
            noteName: CHROMATIC_SCALE[noteIndex] + octave,
            noteBase: CHROMATIC_SCALE[noteIndex],
            activePulses: [],
          };
          this.scene.add(sphere);
          chunkSpheres.push(sphere);
        }
        this.worldGrid.set(key, chunkSpheres);
        console.log('✅ Chunk generated:', key, 'with', chunkSpheres.length, 'spheres. Total chunks:', this.worldGrid.size);
      },

      removeChunk(key) {
        if (!this.worldGrid.has(key)) return;
        this.worldGrid.get(key).forEach(sphere => {
          this.scene.remove(sphere);
          sphere.material.dispose();
        });
        this.worldGrid.delete(key);
      },

      triggerVisualPulse(noteName) {
        const noteBase = noteName.replace(/\d/g, '');
        const color = new THREE.Color(NOTE_COLORS[noteBase] || 0xffffff);
        this.worldGrid.forEach(chunk => {
          chunk.forEach(sphere => {
            if (sphere.userData.noteBase === noteBase) {
              this.lightUpSphereWave(sphere, color, 0);
            }
          });
        });
      },

      lightUpSphereWave(sphere, color, generation) {
        if (generation > 2) return;
        sphere.userData.activePulses.push({
          color,
          startTime: Date.now(),
          intensity: 0.6 - (generation * 0.2)
        });
        const allVisibleSpheres = Array.from(this.worldGrid.values()).flat();
        const neighbors = allVisibleSpheres.map(other => ({
          sphere: other,
          dist: sphere.position.distanceTo(other.position)
        })).filter(item => item.sphere !== sphere && item.dist < this.CHUNK_SIZE / 2)
          .sort((a, b) => a.dist - b.dist)
          .slice(0, 4)
          .map(item => item.sphere);
        
        setTimeout(() => {
          neighbors.forEach(neighbor => this.lightUpSphereWave(neighbor, color, generation + 1));
        }, 150);
      },

      updateWorldGrid(isInitialLoad = false) {
        const camChunk = {
          x: Math.round(this.camera.position.x / this.CHUNK_SIZE),
          y: Math.round(this.camera.position.y / this.CHUNK_SIZE),
          z: Math.round(this.camera.position.z / this.CHUNK_SIZE),
        };
        for (let x = camChunk.x - this.VIEW_DISTANCE; x <= camChunk.x + this.VIEW_DISTANCE; x++) {
          for (let y = camChunk.y - this.VIEW_DISTANCE; y <= camChunk.y + this.VIEW_DISTANCE; y++) {
            for (let z = camChunk.z - this.VIEW_DISTANCE; z <= camChunk.z + this.VIEW_DISTANCE; z++) {
              this.generateChunk(x, y, z);
            }
          }
        }
      },

      animate() {
        requestAnimationFrame(() => this.animate());
        
        // Log every 60 frames (roughly every second)
        if (!this.frameCount) this.frameCount = 0;
        this.frameCount++;
        if (this.frameCount % 60 === 0) {
          console.log('🎬 Animation frame', this.frameCount, '- chunks:', this.worldGrid.size, 'spheres visible:', Array.from(this.worldGrid.values()).flat().length);
        }
        
        // Process visual queue from melody system
        while (AppState.visualQueue.length > 0) {
          const note = AppState.visualQueue.shift();
          this.triggerVisualPulse(note);
        }
        
        this.updateWorldGrid();
        
        // Update sphere colors based on active pulses
        const now = Date.now();
        const allSpheres = Array.from(this.worldGrid.values()).flat();
        allSpheres.forEach(sphere => {
          let finalColor = this.baseSphereColor.clone();
          
          if (sphere.userData.activePulses.length > 0) {
            sphere.userData.activePulses = sphere.userData.activePulses.filter(pulse => {
              const age = now - pulse.startTime;
              const maxAge = 1500;
              if (age < maxAge) {
                const intensity = (1.0 - (age / maxAge)) * pulse.intensity;
                finalColor.add(pulse.color.clone().multiplyScalar(intensity));
                return true;
              }
              return false;
            });
          }
          
          sphere.material.color.lerp(finalColor, 0.2);
        });
        
        // Enhanced camera movement with physics-based randomization
        this.updateCameraMovement();
        
        // Update interactive effects in same loop (performance optimization)
        if (window.InteractiveEffects) {
          InteractiveEffects.updateElements();
        }
        
        this.renderer.render(this.scene, this.camera);
        }
      };
      
      // FIRST: Initialize 3D Background immediately - completely independent of audio
      console.log('🚀 Starting initialization sequence...');
      
      // Get DOM elements - ensure they exist
      const soundToggleBtn = document.getElementById('sound-toggle');
      const soundOnIcon = document.getElementById('sound-on-icon');
      const soundOffIcon = document.getElementById('sound-off-icon');
      const canvas = document.getElementById('bg-canvas');
      
      // Ensure canvas exists before proceeding
      if (!canvas) {
        console.error('❌ Canvas element not found!');
        return;
      }
      
      // Initialize 3D Background FIRST, before sound engine
      console.log('🌟 Initializing 3D Background (BEFORE audio)...');
      ThreeDBackground.init();
      
      // Sound Engine Class
      class SoundEngine {
        constructor() {
          this.synths = {};
          this.effects = {};
          this.melodySequence = null;
          this.isSetup = false;
          this.isEnabled = false;
        }

        async setup() {
          if (this.isSetup) return;
          try {
            await Tone.start();
            
            this.effects.reverb = new Tone.Reverb(AUDIO_CONFIG.effects.reverb.roomSize).toDestination();
            this.effects.reverb.wet.value = AUDIO_CONFIG.effects.reverb.wetness;
            
            this.effects.filter = new Tone.AutoFilter(AUDIO_CONFIG.effects.filter.frequency)
              .connect(this.effects.reverb).start();
            
            this.synths.hover = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.hover.type },
              envelope: AUDIO_CONFIG.synths.hover.envelope,
              volume: AUDIO_CONFIG.synths.hover.volume
            }).connect(this.effects.reverb);
            
            this.synths.click = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.click.type },
              envelope: AUDIO_CONFIG.synths.click.envelope,
              volume: AUDIO_CONFIG.synths.click.volume
            }).connect(this.effects.reverb);
            
            this.synths.highClick = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.highClick.type },
              envelope: AUDIO_CONFIG.synths.highClick.envelope,
              volume: AUDIO_CONFIG.synths.highClick.volume
            }).connect(this.effects.reverb);
            
            this.synths.pad = new Tone.PolySynth(Tone.AMSynth, {
              envelope: AUDIO_CONFIG.synths.pad.envelope,
              volume: AUDIO_CONFIG.synths.pad.volume
            }).connect(this.effects.filter);
            
            this.synths.melody = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.melody.type },
              envelope: AUDIO_CONFIG.synths.melody.envelope,
              volume: AUDIO_CONFIG.synths.melody.volume
            }).connect(this.effects.filter);
            
            this.isSetup = true;
            console.log('🎵 Sound Engine initialized');
          } catch (error) {
            console.error('❌ Sound Engine setup failed:', error);
          }
        }

        enable() {
          if (!this.isSetup) { console.warn('Sound engine not setup yet'); return; }
          this.isEnabled = true;
          AppState.isSoundEnabled = true;
          Tone.Destination.mute = false;
          this.startSoundscape();
          document.body.classList.add('sound-is-on');
          console.log('🔊 Sound enabled');
        }

        disable() {
          this.isEnabled = false;
          AppState.isSoundEnabled = false;
          if (this.isSetup) { Tone.Destination.mute = true; this.stopSoundscape(); }
          document.body.classList.remove('sound-is-on');
          console.log('🔇 Sound disabled');
        }

        toggle() { if (this.isEnabled) { this.disable(); } else { this.enable(); } return this.isEnabled; }

        startSoundscape() {
          if (!this.isEnabled || !this.isSetup) return;
          const now = Tone.now();
          this.synths.pad.triggerAttackRelease(['A2', 'C3', 'E3', 'G3'], '4m', now);
          this.synths.pad.triggerAttack(['D2', 'F#2', 'A2', 'C3'], now + Tone.Time('4m').toSeconds());
          this.synths.hover.triggerAttack('D2');
          Tone.Transport.start();
          this.setMelodyForPage(AppState.activePage);
        }

        stopSoundscape() {
          if (!this.isSetup) return;
          this.synths.pad.releaseAll();
          this.synths.hover.volume.rampTo(-60, 0.1);
          if (this.melodySequence) {
            this.melodySequence.stop().dispose();
            this.melodySequence = null;
          }
          Tone.Transport.stop();
        }

        setMelodyForPage(pageId) {
          if (!AppState.isSoundEnabled || !this.isSetup) return;
          
          if (this.melodySequence) {
            this.melodySequence.stop().dispose();
            this.melodySequence = null;
          }
          
          let notes;
          if (pageId === 'work' || pageId === 'hero') {
            notes = TONE_ROWS[AppState.currentToneRowIndex];
          } else {
            const startNoteName = CHROMATIC_SCALE[AppState.wholeToneStartIndex];
            const scale = WHOLE_TONE_SCALES[0].includes(startNoteName) ? WHOLE_TONE_SCALES[0] : WHOLE_TONE_SCALES[1];
            const startIndexInScale = scale.indexOf(startNoteName);
            notes = [];
            for (let i = 0; i < 12; i++) {
              const step = i < 6 ? i : 10 - i;
              const noteIndex = (startIndexInScale + step + scale.length) % scale.length;
              const noteBase = scale[noteIndex];
              const octave = (i < 6 || i === 10) ? '5' : '4';
              notes.push(noteBase + octave);
            }
            AppState.wholeToneStartIndex += AppState.wholeToneDirection;
            if (AppState.wholeToneStartIndex >= 11) {
              AppState.wholeToneDirection = -1;
              AppState.wholeToneStartIndex = 11;
            } else if (AppState.wholeToneStartIndex <= 0) {
              AppState.wholeToneDirection = 1;
              AppState.wholeToneStartIndex = 0;
            }
          }
          
          this.melodySequence = new Tone.Sequence((time, note) => {
            this.synths.melody.triggerAttackRelease(note, "8n", time);
            Tone.Draw.schedule(() => {
              AppState.visualQueue.push(note);
            }, time);
          }, notes, '4n').start(0);
          this.melodySequence.loop = true;
        }

        playHoverSound() { if (this.synths.hover && this.isEnabled) this.synths.hover.volume.rampTo(-24, 0.5); }
        stopHoverSound() { if (this.synths.hover && this.isEnabled) this.synths.hover.volume.rampTo(-60, 0.8); }
        playClickSound() { if (this.isEnabled) { this.synths.click?.triggerAttackRelease('G3', '0.5'); this.synths.highClick?.triggerAttackRelease('G5', '0.5'); } }
      }

      // Initialize sound engine (non-blocking)
      const soundEngine = new SoundEngine();
      // Setup sound engine asynchronously without blocking other systems
      soundEngine.setup().then(() => {
        console.log('🎵 Sound engine ready');
      }).catch(error => {
        console.warn('🎵 Sound engine setup failed:', error);
      });

      // Mobile Menu System
      const MobileMenu = {
        init() {
          const mobileMenuButton = document.getElementById('mobile-menu-button');
          const mobileMenu = document.getElementById('mobile-menu');
          
          if (!mobileMenuButton || !mobileMenu) {
            console.warn('Mobile menu elements not found');
            return;
          }
          
          mobileMenuButton.addEventListener('click', () => {
            this.toggleMenu();
          });
          
          // Close mobile menu when clicking on links
          const mobileMenuLinks = mobileMenu.querySelectorAll('a');
          mobileMenuLinks.forEach(link => {
            link.addEventListener('click', () => {
              this.closeMenu();
            });
          });
          
          // Close menu when clicking outside
          document.addEventListener('click', (e) => {
            if (!mobileMenuButton.contains(e.target) && !mobileMenu.contains(e.target)) {
              this.closeMenu();
            }
          });
        },
        
        toggleMenu() {
          const mobileMenu = document.getElementById('mobile-menu');
          mobileMenu.classList.toggle('hidden');
          mobileMenu.classList.toggle('flex');
          
          // INSTANT visual feedback
          if (AppState.visualQueue) {
            AppState.visualQueue.push('A4');
            setTimeout(() => AppState.visualQueue.push('D4'), 100);
          }
          
          // Play sound feedback
          if (soundEngine && soundEngine.isEnabled) {
            soundEngine.playClickSound();
          }
        },
        
        closeMenu() {
          const mobileMenu = document.getElementById('mobile-menu');
          mobileMenu.classList.add('hidden');
          mobileMenu.classList.remove('flex');
        },
        
        openMenu() {
          const mobileMenu = document.getElementById('mobile-menu');
          mobileMenu.classList.remove('hidden');
          mobileMenu.classList.add('flex');
        }
      };

      // Advanced Interactive Effects System
      const InteractiveEffects = {
        rainbowElements: [],
        
        init() {
          this.rainbowElements = Array.from(document.querySelectorAll('.interactive-rainbow'));
          
          // Initialize each rainbow element with physics data
          this.rainbowElements.forEach(el => {
            const rect = el.getBoundingClientRect();
            Object.assign(el.dataset, {
              angle: '0',
              x: rect.width / 2,
              y: rect.height / 2,
              targetX: rect.width / 2,
              targetY: rect.height / 2,
              velocityX: '0',
              velocityY: '0'
            });
            
            // Set initial CSS custom properties
            el.style.setProperty('--x', `${rect.width / 2}px`);
            el.style.setProperty('--y', `${rect.height / 2}px`);
            el.style.setProperty('--angle', '0deg');
            
            // Add mouse event listeners
            el.addEventListener('mouseenter', (e) => this.onMouseEnter(e));
            el.addEventListener('mouseleave', (e) => this.onMouseLeave(e));
            el.addEventListener('mousemove', (e) => this.onMouseMove(e));
          });
          
          // Make globally available for shared animation loop
          window.InteractiveEffects = this;
          
          // Invalidate cached rects on window resize
          window.addEventListener('resize', () => {
            this.rainbowElements.forEach(el => {
              delete el._cachedRect;
            });
          });
          
          console.log('✨ Interactive Effects initialized with', this.rainbowElements.length, 'elements (using shared animation loop)');
        },
        
        onMouseEnter(e) {
          const el = e.currentTarget;
          this.updateRainbowTarget(el, e);
        },
        
        onMouseLeave(e) {
          const el = e.currentTarget;
          this.resetRainbowTarget(el);
        },
        
        onMouseMove(e) {
          const el = e.currentTarget;
          this.updateRainbowTarget(el, e);
        },
        
        updateRainbowTarget(el, e) {
          // Optimized: Cache rect and use physics object directly
          if (!el._cachedRect) {
            el._cachedRect = el.getBoundingClientRect();
          }
          if (el._physics) {
            el._physics.targetX = e.clientX - el._cachedRect.left;
            el._physics.targetY = e.clientY - el._cachedRect.top;
          }
        },
        
        resetRainbowTarget(el) {
          if (!el._cachedRect) {
            el._cachedRect = el.getBoundingClientRect();
          }
          if (el._physics) {
            el._physics.targetX = el._cachedRect.width / 2;
            el._physics.targetY = el._cachedRect.height / 2;
          }
        },
        
        animate() {
          // Optimized: Use single animation loop shared with 3D background
          this.updateElements();
        },
        
        updateElements() {
          // Optimized: Process elements only when needed, reduce DOM operations
          this.rainbowElements.forEach(el => {
            // Use numeric properties instead of dataset strings
            if (!el._physics) {
              el._physics = {
                angle: 0,
                x: parseFloat(el.dataset.x),
                y: parseFloat(el.dataset.y),
                targetX: parseFloat(el.dataset.targetX),
                targetY: parseFloat(el.dataset.targetY),
                velocityX: 0,
                velocityY: 0
              };
            }
            
            const p = el._physics;
            
            // Update angle (continuous rotation)
            p.angle += 0.5;
            
            // Physics-based movement towards target
            const forceX = (p.targetX - p.x) * 0.01;
            const forceY = (p.targetY - p.y) * 0.01;
            
            p.velocityX = (p.velocityX + forceX) * 0.92;
            p.velocityY = (p.velocityY + forceY) * 0.92;
            
            p.x += p.velocityX;
            p.y += p.velocityY;
            
            // Batch DOM updates - only update CSS properties
            el.style.setProperty('--angle', `${p.angle}deg`);
            el.style.setProperty('--x', `${p.x}px`);
            el.style.setProperty('--y', `${p.y}px`);
          });
        },
        
        setupDeviceOrientation() {
          // Only for mobile devices
          if (!('ontouchstart' in window)) return;
          
          // Request permission for iOS devices
          if (typeof DeviceOrientationEvent.requestPermission === 'function') {
            DeviceOrientationEvent.requestPermission()
              .then(permissionState => {
                if (permissionState === 'granted') {
                  window.addEventListener('deviceorientation', (e) => this.onDeviceMove(e));
                  console.log('📱 Device orientation enabled');
                }
              })
              .catch(console.error);
          } else {
            // For Android and other devices
            window.addEventListener('deviceorientation', (e) => this.onDeviceMove(e));
            console.log('📱 Device orientation enabled');
          }
        },
        
        onDeviceMove(event) {
          if (event.gamma === null) return;
          
          // Convert gamma (left-right tilt) to a normalized value
          const tilt = Math.max(-60, Math.min(60, event.gamma));
          const normalizedTilt = tilt / 60; // Range: -1 to 1
          
          // Apply subtle device tilt effect to all rainbow elements
          this.rainbowElements.forEach(el => {
            const rect = el.getBoundingClientRect();
            const centerX = rect.width / 2;
            const offsetX = centerX + (normalizedTilt * rect.width * 0.3);
            
            // Update target position based on device orientation
            el.dataset.targetX = Math.max(0, Math.min(rect.width, offsetX)).toString();
          });
        }
      };

      // Loading Animation System
      const LoadingSystem = {
        activeAnimations: new Set(),
        
        async showLoadingAnimation(options = {}) {
          const animationId = Date.now() + Math.random();
          this.activeAnimations.add(animationId);
          
          const {
            duration = 2000,
            showExplosion = true,
            playMusic = true,
            message = 'Loading...',
            callback = null
          } = options;
          
          // Each animation has its own ID, no global blocking
          
          const loadingOverlay = document.getElementById('loading-overlay');
          const explosionBg = document.getElementById('explosion-background');
          const progressBar = document.getElementById('loading-bar-progress');
          const loadingText = loadingOverlay.querySelector('.text-white');
          
          if (!loadingOverlay || !explosionBg || !progressBar) {
            console.warn('Loading elements not found');
            this.activeAnimations.delete(animationId);
            return Promise.resolve();
          }
          
          // Update loading message
          loadingText.textContent = message;
          
          // Show loading overlay
          loadingOverlay.classList.remove('hidden');
          loadingOverlay.classList.add('flex');
          
          // Show explosion background if requested
          if (showExplosion) {
            explosionBg.classList.add('exploding');
          }
          
          // Fade in overlay
          setTimeout(() => {
            loadingOverlay.style.opacity = '1';
            progressBar.style.width = '100%';
          }, 10);
          
          // Play musical accompaniment
          if (playMusic && soundEngine && soundEngine.isEnabled) {
            this.playLoadingMusic();
          }
          
          // Return promise that resolves when loading is complete
          return new Promise((resolve) => {
            setTimeout(() => {
              // Fade out
              loadingOverlay.style.opacity = '0';
              
              setTimeout(() => {
                // Hide elements
                loadingOverlay.classList.add('hidden');
                loadingOverlay.classList.remove('flex');
                explosionBg.classList.remove('exploding');
                progressBar.style.width = '0%';
                
                this.activeAnimations.delete(animationId);
                
                // Execute callback if provided
                if (callback) {
                  callback();
                }
                
                resolve();
              }, 150);
            }, duration);
          });
        },
        
        playLoadingMusic() {
          if (!soundEngine || !soundEngine.isEnabled) return;
          
          const now = Tone.now();
          
          // Play musical sequence inspired by the original
          const loadingNotes = ['C4', 'E4', 'G4', 'C5', 'G4', 'E4', 'C4', 'G3'];
          
          loadingNotes.forEach((note, index) => {
            setTimeout(() => {
              if (soundEngine.synths.melody) {
                soundEngine.synths.melody.triggerAttackRelease(note, '16n');
                
                // Trigger visual pulse in background
                if (AppState.visualQueue) {
                  AppState.visualQueue.push(note);
                }
              }
            }, index * 200);
          });
          
          // Add some sparkle with the high click synth
          setTimeout(() => {
            if (soundEngine.synths.highClick) {
              ['C6', 'E6', 'G6'].forEach((note, index) => {
                setTimeout(() => {
                  soundEngine.synths.highClick.triggerAttackRelease(note, '32n');
                }, index * 150);
              });
            }
          }, 800);
        },
        
        // Quick loading for page transitions
        showQuickLoading(message = 'Transitioning...') {
          return this.showLoadingAnimation({
            duration: 600,
            showExplosion: false,
            playMusic: false,
            message
          });
        },
        
        // Full loading with all effects
        showFullLoading(message = 'Loading...', callback = null) {
          return this.showLoadingAnimation({
            duration: 800,
            showExplosion: true,
            playMusic: true,
            message,
            callback
          });
        }
      };

      // Blog post data - loaded from Eleventy
      const BlogData = {
        posts: [
          {
            title: "The Art of Improvisation",
            date: "December 31, 2024",
            url: "/posts/improvisation/",
            image: "images/pic04.jpg",
            videoId: "",
            tags: ["post","Music Theory","Creativity"],
            content: "<p>This webpage is under construction. Check back soon to learn more about jazz improvisation and our process of creativity.</p>\n"
          },{
            title: "Devlog: Trumpet Test in MR",
            date: "May 14, 2021",
            url: "/posts/devlog-2021-05-15/",
            image: "",
            videoId: "jM_3Ma0daAA",
            tags: ["post","Devlog","Portraits of Change"],
            content: "<p>Check out our latest trumpet test in mixed reality! A little Haydn in color.</p>\n"
          },{
            title: "Devlog: VFX MIDI Tests",
            date: "April 14, 2021",
            url: "/posts/devlog-2021-04-15/",
            image: "",
            videoId: "l-iUqews7Q0",
            tags: ["post","Devlog","Portraits of Change"],
            content: "<p>This video contains a collection of different effects I've made for Portraits. In this 2D Unity scene, I can test different MIDI driven VFX without needing VR. There isn't sound, but these effects are being driven by my MIDI keyboard in real-time.</p>\n"
          },{
            title: "Devlog: University Demo",
            date: "April 11, 2021",
            url: "/posts/devlog-2021-04-12/",
            image: "",
            videoId: "xYRqNQzCxVM",
            tags: ["post","Devlog","Update"],
            content: "<p>I got to bring my VR/AR rig down to my university to demonstrate a VR conducting app I have been working on for a class, and couldn't help myself in sharing some Portraits stuff as well! Here is a short demonstration of the Portraits of Change beta software and AR prototype with the man who taught me piano, Greg Creager! The past year has been very challenging on all of us... I shifted gears, and started working on an educational tool to help teach basic conducting... With the pandemic soon recessing as we ramp up vaccinations, the prospect of live performance with live audiences becomes possible again. There will be a Portraits performance as my senior recital by the end of the year.</p>\n"
          },{
            title: "Devlog: Coronavirus Update",
            date: "April 26, 2020",
            url: "/posts/devlog-2020-04-27/",
            image: "",
            videoId: "RUBBKnUVU-s",
            tags: ["post","Devlog","Update"],
            content: "<p>Well, that happened. Coronavirus has altered our way of life, and the performing arts have suffered. The prospects of live music performance are not looking great... I am still working through Portraits, hoping to attain some Vive trackers and adding more visual effects and refining the AR pass-through prototype. In our recent update, I added HDRP support and am using VFX graphs exclusively for the particle system.</p>\n"
          },{
            title: "Devlog: SteamVR Tracking",
            date: "March 26, 2020",
            url: "/posts/devlog-2020-03-27/",
            image: "",
            videoId: "C5lcmrWpCXE",
            tags: ["post","Devlog","Hardware"],
            content: "<p>We have upgraded to SteamVR tracking! With the addition of the Index headset to our mixed reality arsenal, we can start prototyping AR pass-through with the ZED mini and LEAP motion sensor in a well-tracked environment with multiple objects in scene.</p>\n"
          },{
            title: "Devlog: Multi-Instrument Harmony",
            date: "February 4, 2020",
            url: "/posts/devlog-2020-02-05/",
            image: "",
            videoId: "FFIsxg-flIg",
            tags: ["post","Devlog","Milestone"],
            content: "<p>I managed to get a recording with our session pianist Noah Suazo. It was a really great experience and really rich to finally see some multi instrument harmony in action. We are both energized to see what more of our music looks like! I also used footage from this session for my Peak Arts Prize 2020 proposal.</p>\n"
          },{
            title: "Devlog: Trumpet Module",
            date: "January 8, 2020",
            url: "/posts/devlog-2020-01-09/",
            image: "",
            videoId: "IxDf7hlPQLw",
            tags: ["post","Devlog","Milestone"],
            content: "<p>This is where things get good. A little over a full year has past and we have a fully functioning trumpet module working! 0.2.5 will also be our first multi-instrument supported version.</p>\n"
          },{
            title: "Devlog: Post-Festival Update",
            date: "September 14, 2019",
            url: "/posts/devlog-2019-09-15/",
            image: "",
            videoId: "VPJgtfEtFgQ",
            tags: ["post","Devlog","Event"],
            content: "<p>With the What If... Festival wrapped up, we are bunkering down to develop our MIDI conversion system after all this time researching and prototyping on piano. 0.2.4 will see the addition of the trumpet along with bug fixes and updates to the performance mode of Portraits of Change.</p>\n"
          },{
            title: "Devlog: AR MIDI Color Test",
            date: "August 24, 2019",
            url: "/posts/devlog-2019-08-25/",
            image: "",
            videoId: "Q6Wat4iVT-M",
            tags: ["post","Devlog","AR"],
            content: "<p>We have been hard at work testing our MIDI color system in augmented reality, while still polishing the VR experience for our upcoming events. We were fortunate to host our session pianist Noah Suazo for our most recent test, to uncover the possibilities of augmented reality! This test was used with the LIV software, and it is a really incredible tool for mixed reality recording.</p>\n"
          },{
            title: "Devlog: Fundraising & First Event",
            date: "July 10, 2019",
            url: "/posts/devlog-2019-07-11/",
            image: "",
            videoId: "NMaVNASWMLU",
            tags: ["post","Devlog","Update"],
            content: "<p>July Update- It has been a busy summer for Portraits of Change! We have officially reached our first fundraising milestone- to raise $1000! We also have our first event finalized! On September 14th, 2019, you can find a booth of Portraits of Change at the What If... Festival of Innovation &amp; Imagination in Downtown Colorado Springs!</p>\n"
          },{
            title: "Devlog: Initial Prototype",
            date: "April 14, 2019",
            url: "/posts/devlog-2019-04-15/",
            image: "",
            videoId: "3-ZnpXlRGYI",
            tags: ["post","Devlog","Prototype"],
            content: "<p>We had made some breakthroughs in developing an initial prototype of the idea of incorporating VR/AR into a live music performance. With help of some incredible developers and through the discovery of amazing open-sourced projects and samples, I was able to build a Frankenstein of a Unity project that actually works! MIDI turned out to be a key player in utilizing physical interfaces to generate low-latency effects directly from the music itself.</p>\n"
          },{
            title: "Why Jazz? A History of Innovation",
            date: "March 14, 2019",
            url: "/posts/why-jazz/",
            image: "images/pic04.jpg",
            videoId: "",
            tags: ["post","Music","History","Philosophy"],
            content: "<p>You may be wondering what all the fuss is about. Is it &quot;elevator music&quot;? Is it for pretentious cocktail parties? After learning its history, you decide.</p>\n<p>Jazz sits at the center of Portraits of Change. What evolved between a confrontation in culture led to a syncretism of art. As technology continues to develop in both the music world and in other fields, there arises a need to continue Jazz's cultural heritage in new, dynamic ways.</p>\n<p>Portraits of Change initially started as a recital focused on music innovation. I wanted to highlight past innovative works within jazz, and try to paint a &quot;portrait&quot; of the composer through their own music. A portrait can be defined as a painting, drawing, photo, or visual representation of a person usually depicting only the face or head and shoulders. A more abstract definition is a representation or impression of someone. That is exactly what we set out with our audiovisual environments, to paint with sound and light an impression of the mood and likeness of the composer.</p>\n<blockquote>\n<p>&quot;If a Jazz musician plays someone else's song, he has a responsibility to make a distinct &amp; original statement.&quot;</p>\n</blockquote>\n<p>I hope that by adding a visual component to the music, it makes it more accessible to untrained ears and more enjoyable and immersive for everyone. I hope to spark joy and interest in these wonderful musicians throughout time that have inspired me and to foster more listeners to their music through this medium of mixed reality and music.</p>\n"
          },
        ]
      };

      // Simple Page Manager - just handles sound and basic interactions
      const PageManager = {
        init() {
          AppState.currentToneRowIndex = Math.floor(Math.random() * TONE_ROWS.length);
          AppState.activePage = 'hero';
          
          // Set melody based on current page
          const path = window.location.pathname;
          if (path.includes('/work')) {
            AppState.activePage = 'work';
          } else if (path.includes('/about')) {
            AppState.activePage = 'about';  
          } else if (path.includes('/blog')) {
            AppState.activePage = 'blog';
          }
          
          soundEngine.setMelodyForPage(AppState.activePage);
          
          // Load blog content if on blog page
          if (AppState.activePage === 'blog') {
            this.loadBlogContent();
          }
        },

        loadBlogContent() {
          const blogGrid = document.getElementById('blog-grid');
          if (!blogGrid) return;

          blogGrid.innerHTML = BlogData.posts.map(post => {
            let imageUrl = 'images/pic01.jpg';
            if (post.videoId && post.videoId !== '') {
              imageUrl = `https://img.youtube.com/vi/${post.videoId}/maxresdefault.jpg`;
            } else if (post.image && post.image !== '') {
              imageUrl = post.image;
            }

            return `
              <article class="bg-[var(--color-bg-card)] rounded-xl overflow-hidden hover:shadow-lg transition-shadow duration-300 group">
                <div class="relative">
                  <img src="${imageUrl}" alt="${post.title}" class="w-full h-48 object-cover group-hover:scale-105 transition-transform duration-300">
                  ${post.videoId && post.videoId !== '' ? `
                    <div class="absolute inset-0 flex items-center justify-center">
                      <div class="bg-red-600 rounded-full p-3 shadow-lg">
                        <svg class="w-8 h-8 text-white ml-1" fill="currentColor" viewBox="0 0 20 20">
                          <path d="M6.3 2.841A1.5 1.5 0 004 4.11V15.89a1.5 1.5 0 002.3 1.269l9.344-5.89a1.5 1.5 0 000-2.538L6.3 2.841z"/>
                        </svg>
                      </div>
                    </div>
                  ` : ''}
                </div>
                <div class="p-6">
                  <div class="flex flex-wrap gap-2 mb-3">
                    ${post.tags.filter(tag => tag !== 'post').map(tag => `<span class="inline-block bg-[var(--color-secondary)] text-xs font-medium px-2.5 py-1 rounded-full">${tag}</span>`).join('')}
                  </div>
                  <h3 class="text-xl font-bold text-white mb-2 group-hover:text-gray-300 transition-colors">${post.title}</h3>
                  <p class="text-gray-500 text-sm mb-4">${post.date}</p>
                  <a href="${post.url}" class="inline-block sound-interactive interactive-rainbow px-4 py-2 font-semibold text-sm uppercase tracking-wider rounded-lg transition-colors">Read More</a>
                </div>
              </article>
            `;
          }).join('');
        }
      };

      // Setup event listeners - ensure sound engine is setup first
      soundToggleBtn.addEventListener('click', async () => {
        try {
          if (!soundEngine.isSetup) {
            console.log('🎵 Setting up sound engine...');
            await soundEngine.setup();
          }
          
          // Explicitly handle first-time activation
          if (!soundEngine.isEnabled) {
            soundEngine.enable();
            console.log('🔊 Sound enabled on first click');
          } else {
            soundEngine.disable();
            console.log('🔇 Sound disabled');
          }
          
          // Update UI
          const isEnabled = soundEngine.isEnabled;
          soundOnIcon.classList.toggle('hidden', !isEnabled);
          soundOffIcon.classList.toggle('hidden', isEnabled);
        } catch (error) {
          console.error('❌ Sound toggle failed:', error);
        }
      });

      // Sound interaction events
      document.body.addEventListener('mouseover', e => {
        if (e.target.closest('.sound-interactive')) {
          soundEngine.playHoverSound();
        }
      });

      document.body.addEventListener('mouseout', e => {
        if (e.target.closest('.sound-interactive')) {
          soundEngine.stopHoverSound();
        }
      });

      document.body.addEventListener('click', e => {
        if (e.target.closest('.sound-interactive')) {
          // INSTANT visual feedback - trigger background pulse immediately
          if (AppState.visualQueue) {
            AppState.visualQueue.push('C4'); // Instant visual pulse
            setTimeout(() => AppState.visualQueue.push('G4'), 150);
            setTimeout(() => AppState.visualQueue.push('E4'), 300);
          }
          
          // Sound response (async, won't block visual)
          soundEngine.playClickSound();
        }
      });

      // Reality Engine Button with Loading System
      const realityEngineBtn = document.getElementById('reality-engine-btn');
      const noVrModal = document.getElementById('no-vr-modal');
      const closeNoVrModalBtn = document.getElementById('close-no-vr-modal');
      
      if (realityEngineBtn) {
        realityEngineBtn.addEventListener('click', async (e) => {
          e.preventDefault();
          
          // INSTANT visual feedback - trigger background explosion immediately
          if (AppState.visualQueue) {
            // Powerful burst sequence for Reality Engine
            const engineNotes = ['C4', 'E4', 'G4', 'C5', 'E5', 'G5'];
            engineNotes.forEach((note, index) => {
              setTimeout(() => AppState.visualQueue.push(note), index * 80);
            });
          }
          
          // INSTANT visual feedback - start loading animation immediately  
          const loadingPromise = LoadingSystem.showFullLoading('Initializing Reality Engine...');
          
          // PARALLEL execution - all these happen while animation runs
          const soundSetupPromise = (async () => {
            if (!AppState.isSoundEnabled) {
              await soundEngine.setup();
              soundEngine.enable();
              document.getElementById('sound-off-icon').classList.add('hidden');
              document.getElementById('sound-on-icon').classList.remove('hidden');
            }
            soundEngine.playClickSound();
          })();
          
          const pagePreloadPromise = fetch('/work/');
          
          const webxrCheckPromise = (async () => {
            try {
              if (navigator.xr && await navigator.xr.isSessionSupported('immersive-vr')) {
                console.log('✅ WebXR VR session supported');
                return { hasVR: true };
              } else {
                console.log('❌ WebXR not supported');
                return { hasVR: false };
              }
            } catch (error) {
              console.error('WebXR check failed:', error);
              return { hasVR: false };
            }
          })();
          
          // Wait for all parallel operations to complete
          const [loadingResult, soundResult, pageResult, webxrResult] = await Promise.all([
            loadingPromise,
            soundSetupPromise, 
            pagePreloadPromise,
            webxrCheckPromise
          ]);
          
          // Navigate immediately after loading animation completes
          if (webxrResult.hasVR) {
            window.location.href = '/work/';
          } else {
            if (noVrModal) {
              noVrModal.classList.remove('hidden');
            }
          }
        });
      }
      
      // Close VR Modal
      if (closeNoVrModalBtn && noVrModal) {
        closeNoVrModalBtn.addEventListener('click', () => {
          noVrModal.classList.add('hidden');
          soundEngine.playClickSound();
        });
      }

      // Page Transition System
      const PageTransition = {
        isTransitioning: false,
        
        async navigateToPage(url, pushState = true) {
          if (this.isTransitioning) {
            console.log('📄 Navigation already in progress, allowing concurrent requests');
          }
          this.isTransitioning = true;
          
          try {
            // Show loading overlay
            const overlay = document.getElementById('page-transition-overlay');
            const mainContent = document.getElementById('main-content');
            
            overlay.style.pointerEvents = 'all';
            overlay.style.opacity = '0.3';
            mainContent.style.opacity = '0.7';
            
            // Fetch new page content
            const response = await fetch(url);
            if (!response.ok) throw new Error('Failed to load page');
            
            const html = await response.text();
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, 'text/html');
            
            // Extract the new content and title
            const newMainContent = doc.querySelector('main');
            const newTitle = doc.querySelector('title')?.textContent || 'Thomas Graves';
            
            if (!newMainContent) throw new Error('Invalid page structure');
            
            // Update page title and URL
            document.title = newTitle;
            if (pushState) {
              history.pushState({ url }, '', url);
            }
            
            // Close mobile menu if open
            if (typeof MobileMenu !== 'undefined') {
              MobileMenu.closeMenu();
            }
            
            // Trigger visual transition effects
            this.triggerTransitionEffects();
            
            // Fade out completely
            mainContent.style.opacity = '0';
            
            // Wait for fade out (faster)
            await new Promise(resolve => setTimeout(resolve, 150));
            
            // Replace content
            mainContent.innerHTML = newMainContent.innerHTML;
            mainContent.className = newMainContent.className;
            
            // Update active page for music and camera
            const path = url;
            let newPageId;
            if (path.includes('/work')) {
              newPageId = 'work';
            } else if (path.includes('/about')) {
              newPageId = 'about';  
            } else if (path.includes('/blog')) {
              newPageId = 'blog';
            } else {
              newPageId = 'hero';
            }
            
            AppState.activePage = newPageId;
            
            // Set new melody for the page (music continues seamlessly)
            soundEngine.setMelodyForPage(AppState.activePage);
            
            // Animate camera to new page position
            this.animateCameraForPage(newPageId);
            
            // Load blog content if needed
            if (AppState.activePage === 'blog') {
              PageManager.loadBlogContent();
            }
            
            // Reinitialize page-specific functionality
            this.initializePageSpecificScripts();
            
            // Reinitialize interactive effects for new elements
            if (typeof InteractiveEffects !== 'undefined') {
              InteractiveEffects.init();
            }
            
            // Fade in new content
            overlay.style.opacity = '0';
            mainContent.style.opacity = '1';
            
            // Clean up overlay (faster)
            setTimeout(() => {
              overlay.style.pointerEvents = 'none';
            }, 200);
            
          } catch (error) {
            console.error('Navigation error:', error);
            // Fallback to normal navigation
            window.location.href = url;
          } finally {
            this.isTransitioning = false;
          }
        },
        
        init() {
          // Intercept navigation clicks
          document.addEventListener('click', (e) => {
            const link = e.target.closest('a[href]');
            if (!link) return;
            
            const href = link.getAttribute('href');
            
            // Only intercept internal links
            if (!href || href.startsWith('http') || href.startsWith('mailto:') || href.startsWith('#')) {
              return;
            }
            
            // Don't intercept if ctrl/cmd/shift clicked (user wants new tab)
            if (e.ctrlKey || e.metaKey || e.shiftKey) return;
            
            e.preventDefault();
            this.navigateToPage(href);
          });
          
          // Handle browser back/forward buttons
          window.addEventListener('popstate', (e) => {
            if (e.state && e.state.url) {
              this.navigateToPage(e.state.url, false);
            } else {
              this.navigateToPage(window.location.pathname, false);
            }
          });
          
          // Store initial state
          history.replaceState({ url: window.location.pathname }, '', window.location.pathname);
        },
        
        initializePageSpecificScripts() {
          // Initialize project page toggle functionality
          this.initProjectPageToggles();
        },
        
        initProjectPageToggles() {
          // Development log data for Portraits of Change
          const devlogData = [
            { id: '2021-05-15', title: 'Devlog: Trumpet Test in MR', date: 'May 15, 2021', videoId: 'jM_3Ma0daAA', text: "Check out our latest trumpet test in mixed reality! A little Haydn in color.", tags: ['Devlog', 'Portraits of Change'] },
            { id: '2021-04-15', title: 'Devlog: VFX MIDI Tests', date: 'April 15, 2021', videoId: 'l-iUqews7Q0', text: "This video contains a collection of different effects I've made for Portraits. In this 2D Unity scene, I can test different MIDI driven VFX without needing VR. There isn't sound, but these effects are being driven by my MIDI keyboard in real-time.", tags: ['Devlog', 'Portraits of Change'] },
            { id: '2021-04-12', title: 'Devlog: University Demo', date: 'April 12, 2021', videoId: 'xYRqNQzCxVM', text: "I got to bring my VR/AR rig down to my university to demonstrate a VR conducting app I have been working on for a class, and couldn't help myself in sharing some Portraits stuff as well!", tags: ['Devlog', 'Update'] },
            { id: '2020-04-27', title: 'Devlog: Coronavirus Update', date: 'April 27, 2020', videoId: 'RUBBKnUVU-s', text: "Well, that happened. Coronavirus has altered our way of life, and the performing arts have suffered. The prospects of live music performance are not looking great...", tags: ['Devlog', 'Update'] },
            { id: '2020-03-27', title: 'Devlog: SteamVR Tracking', date: 'March 27, 2020', videoId: 'C5lcmrWpCXE', text: "We have upgraded to SteamVR tracking! With the addition of the Index headset to our mixed reality arsenal, we can start prototyping AR pass-through with the ZED mini and LEAP motion sensor.", tags: ['Devlog', 'Hardware'] },
            { id: '2020-02-05', title: 'Devlog: Multi-Instrument Harmony', date: 'February 5, 2020', videoId: 'FFIsxg-flIg', text: "I managed to get a recording with our session pianist Noah Suazo. It was a really great experience and really rich to finally see some multi instrument harmony in action.", tags: ['Devlog', 'Milestone'] },
            { id: '2020-01-09', title: 'Devlog: Trumpet Module', date: 'January 9, 2020', videoId: 'IxDf7hlPQLw', text: "This is where things get good. A little over a full year has past and we have a fully functioning trumpet module working! 0.2.5 will also be our first multi-instrument supported version.", tags: ['Devlog', 'Milestone'] },
            { id: '2019-09-15', title: 'Devlog: Post-Festival Update', date: 'September 15, 2019', videoId: 'VPJgtfEtFgQ', text: "With the What If... Festival wrapped up, we are bunkering down to develop our MIDI conversion system after all this time researching and prototyping on piano.", tags: ['Devlog', 'Event'] },
            { id: '2019-08-25', title: 'Devlog: AR MIDI Color Test', date: 'August 25, 2019', videoId: 'Q6Wat4iVT-M', text: "We have been hard at work testing our MIDI color system in augmented reality, while still polishing the VR experience for our upcoming events.", tags: ['Devlog', 'AR'] },
            { id: '2019-07-11', title: 'Devlog: Fundraising & First Event', date: 'July 11, 2019', videoId: 'NMaVNASWMLU', text: "July Update- It has been a busy summer for Portraits of Change! We have officially reached our first fundraising milestone- to raise $1000!", tags: ['Devlog', 'Update'] },
            { id: '2019-04-15', title: 'Devlog: Initial Prototype', date: 'April 15, 2019', videoId: '3-ZnpXlRGYI', text: "We had made some breakthroughs in developing an initial prototype of the idea of incorporating VR/AR into a live music performance.", tags: ['Devlog', 'Prototype'] }
          ];

          // Get toggle elements
          const devlogBtn = document.getElementById('toggle-devlog-btn');
          const collaboratorsBtn = document.getElementById('toggle-collaborators-btn');
          const devlogSection = document.getElementById('devlog-section');
          const collaboratorsSection = document.getElementById('collaborators-section');
          const devlogGrid = document.getElementById('devlog-grid');

          // Populate devlog grid if it exists
          if (devlogGrid && devlogGrid.children.length === 0) {
            devlogGrid.innerHTML = devlogData.map(entry => `
              <div class="bg-[var(--color-bg-card)] border border-[var(--color-border)] p-4 flex flex-col rounded-lg group">
                <div class="aspect-w-16 aspect-h-9 rounded-lg overflow-hidden mb-3 bg-black">
                  <img src="https://img.youtube.com/vi/${entry.videoId}/hqdefault.jpg" alt="Thumbnail for ${entry.title}" class="w-full h-full object-cover">
                </div>
                <p class="text-xs text-gray-500 mb-2">${entry.date}</p>
                <h4 class="font-bold text-md text-white mb-3 uppercase tracking-wide flex-grow">${entry.title}</h4>
                <p class="text-gray-400 text-sm mb-3">${entry.text}</p>
                <a href="https://www.youtube.com/watch?v=${entry.videoId}" target="_blank" class="text-indigo-400 text-sm font-semibold hover:text-indigo-300 mt-auto">Watch Video &rarr;</a>
              </div>
            `).join('');
          }

          // Remove any existing event listeners to prevent duplicates
          if (devlogBtn) {
            devlogBtn.replaceWith(devlogBtn.cloneNode(true));
            const newDevlogBtn = document.getElementById('toggle-devlog-btn');
            newDevlogBtn.addEventListener('click', () => {
              const isHidden = devlogSection.classList.contains('hidden');
              devlogSection.classList.toggle('hidden');
              newDevlogBtn.textContent = isHidden ? 'Hide Development Log' : 'View Development Log';
              
              if (!isHidden && collaboratorsSection && !collaboratorsSection.classList.contains('hidden')) {
                collaboratorsSection.classList.add('hidden');
                if (collaboratorsBtn) collaboratorsBtn.textContent = 'View Collaborators';
              }
            });
          }

          if (collaboratorsBtn) {
            collaboratorsBtn.replaceWith(collaboratorsBtn.cloneNode(true));
            const newCollaboratorsBtn = document.getElementById('toggle-collaborators-btn');
            newCollaboratorsBtn.addEventListener('click', () => {
              const isHidden = collaboratorsSection.classList.contains('hidden');
              collaboratorsSection.classList.toggle('hidden');
              newCollaboratorsBtn.textContent = isHidden ? 'Hide Collaborators' : 'View Collaborators';
              
              if (!isHidden && devlogSection && !devlogSection.classList.contains('hidden')) {
                devlogSection.classList.add('hidden');
                if (devlogBtn) document.getElementById('toggle-devlog-btn').textContent = 'View Development Log';
              }
            });
          }
        },
        
        animateCameraForPage(pageId) {
          // Define camera positions for different pages (more dynamic than original)
          const cameraPositions = {
            'hero': { x: 0, y: 0, z: 2 },
            'work': { x: -2, y: 1, z: 3 },
            'about': { x: 2, y: -1, z: 4 },
            'blog': { x: 0, y: 2, z: 3 }
          };
          
          const targetPos = cameraPositions[pageId] || cameraPositions['hero'];
          
          if (ThreeDBackground && ThreeDBackground.cameraTargetPosition) {
            // Smooth camera transition over 1 second (faster like original)
            const startPos = ThreeDBackground.cameraTargetPosition.clone();
            const endPos = new THREE.Vector3(targetPos.x, targetPos.y, targetPos.z);
            
            let startTime = Date.now();
            const duration = 1000; // 1 second
            
            const animateCamera = () => {
              const elapsed = Date.now() - startTime;
              const progress = Math.min(elapsed / duration, 1);
              
              // Use easeInOutCubic for smooth animation
              const easedProgress = progress < 0.5 
                ? 4 * progress * progress * progress 
                : 1 - Math.pow(-2 * progress + 2, 3) / 2;
              
              const currentPos = startPos.clone().lerp(endPos, easedProgress);
              ThreeDBackground.cameraTargetPosition.copy(currentPos);
              
              if (progress < 1) {
                requestAnimationFrame(animateCamera);
              }
            };
            
            animateCamera();
            
            // Add some visual flair - trigger sphere pulses during camera movement
            setTimeout(() => {
              const randomNotes = ['C4', 'E4', 'G4', 'B4'];
              randomNotes.forEach((note, index) => {
                setTimeout(() => {
                  AppState.visualQueue.push(note);
                }, index * 200);
              });
            }, 300);
          }
        },
        
        triggerTransitionEffects() {
          if (!ThreeDBackground || !ThreeDBackground.scene) return;
          
          // Create a dramatic visual effect during page transitions
          const effectNotes = ['C4', 'D4', 'E4', 'F4', 'G4', 'A4', 'B4', 'C5'];
          
          // Trigger rapid fire note pulses in sequence
          effectNotes.forEach((note, index) => {
            setTimeout(() => {
              AppState.visualQueue.push(note);
              
              // Add some extra intensity by triggering multiple related notes
              if (index % 2 === 0) {
                const harmonicNote = note.replace('4', '3'); // Drop an octave
                setTimeout(() => AppState.visualQueue.push(harmonicNote), 50);
              }
            }, index * 80);
          });
          
          // Add a cascading wave effect after the rapid sequence
          setTimeout(() => {
            const waveNotes = ['G5', 'E5', 'C5', 'A4', 'F4', 'D4'];
            waveNotes.forEach((note, index) => {
              setTimeout(() => AppState.visualQueue.push(note), index * 120);
            });
          }, 600);
        }
      };

      // Initialize remaining systems (3D background already initialized)
      console.log('📄 Initializing Page Manager...');
      PageManager.init();
      
      console.log('🔄 Initializing Page Transitions...');
      PageTransition.init();
      
      console.log('📱 Initializing Mobile Menu...');
      MobileMenu.init();
      
      console.log('✨ Initializing Interactive Effects...');
      InteractiveEffects.init();
      InteractiveEffects.setupDeviceOrientation();
      
      console.log('⚙️ Initializing page-specific scripts...');
      PageTransition.initializePageSpecificScripts();
      
      // Set initial camera position based on current page  
      const currentPath = window.location.pathname;
      let currentPage = 'hero';
      if (currentPath.includes('/work')) {
        currentPage = 'work';
      } else if (currentPath.includes('/about')) {
        currentPage = 'about';  
      } else if (currentPath.includes('/blog')) {
        currentPage = 'blog';
      }
      
      console.log('🎯 Current page detected:', currentPage, 'from path:', currentPath);
      
      // Set initial camera position without animation - immediately
      const cameraPositions = {
        'hero': { x: 0, y: 0, z: 2 },
        'work': { x: -2, y: 1, z: 3 },
        'about': { x: 2, y: -1, z: 4 },
        'blog': { x: 0, y: 2, z: 3 }
      };
      
      const initialPos = cameraPositions[currentPage] || cameraPositions['hero'];
      if (ThreeDBackground && ThreeDBackground.cameraTargetPosition) {
        ThreeDBackground.cameraTargetPosition.set(initialPos.x, initialPos.y, initialPos.z);
        console.log('📷 Camera position set to:', initialPos);
        
        // Force a render after camera position is set
        setTimeout(() => {
          if (ThreeDBackground.renderer && ThreeDBackground.scene && ThreeDBackground.camera) {
            ThreeDBackground.renderer.render(ThreeDBackground.scene, ThreeDBackground.camera);
            console.log('🎬 Forced render completed');
          }
        }, 100);
      }
    });
  </script>
</body>
</html>