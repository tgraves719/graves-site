<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Devlog: Trumpet Test in MR - Thomas Graves</title>
  <!-- Tailwind and fonts -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.7.77/Tone.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  <style>
    :root {
      --color-secondary: #334155;
      --color-border: #27272A;
      --color-bg-card: #18181B;
    }
    body {
      font-family: 'Inter', sans-serif;
      background-color: #0A0A0A;
      color: #E0E0E0;
    }
    #bg-canvas {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: -10;
    }
    .interactive-rainbow {
      position: relative;
      z-index: 1;
      overflow: hidden;
      border: 3px solid transparent;
      color: white;
    }
    .interactive-rainbow::before {
      content: '';
      position: absolute;
      z-index: -2;
      left: 50%;
      top: 50%;
      width: 250%;
      padding-bottom: 250%;
      transform: translate(-50%, -50%);
      background: conic-gradient(
        #ff2a2a, #ff8000, #ffff00, #40ff00,
        #00ffff, #0080ff, #8000ff, #ff00ff, #ff2a2a
      );
      opacity: 0;
      transition: opacity 0.2s ease;
    }
    .interactive-rainbow::after {
      content: '';
      position: absolute;
      z-index: -1;
      inset: 3px;
      background: var(--color-bg-card);
      border-radius: inherit;
    }
    .interactive-rainbow:hover::before {
      opacity: 0.15;
    }
    .nav-link.active.interactive-rainbow::before {
      opacity: 0.25;
    }
  </style>
</head>
<body class="antialiased">
  <canvas id="bg-canvas"></canvas>
  <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 relative z-10">
    <!-- Header -->
    <header class="py-6 sticky top-0 z-50 bg-[#0A0A0A]">
      <nav class="flex justify-between items-center">
        <div class="flex items-center gap-4">
          <a href="/" id="home-link" class="sound-interactive text-2xl font-bold tracking-tighter text-white hover:text-gray-300">Thomas Graves</a>
          <button id="sound-toggle" title="Toggle Sound" class="text-gray-500 hover:text-white transition-colors focus:outline-none">
            <svg id="sound-off-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
              <path stroke-linecap="round" stroke-linejoin="round" d="M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" clip-rule="evenodd" />
              <path stroke-linecap="round" stroke-linejoin="round" d="M17 14l2-2m0 0l2-2m-2 2l-2-2m2 2l2 2" />
            </svg>
            <svg id="sound-on-icon" xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 hidden" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
              <path stroke-linecap="round" stroke-linejoin="round" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z" />
            </svg>
          </button>
        </div>
        <div class="hidden md:flex items-center space-x-2">
          <a href="/work/" class="sound-interactive interactive-rainbow uppercase text-sm tracking-wider px-3 py-2 rounded-md cursor-pointer transition-colors hover:text-white">Work</a>
          <a href="/about/" class="sound-interactive interactive-rainbow uppercase text-sm tracking-wider px-3 py-2 rounded-md cursor-pointer transition-colors hover:text-white">About</a>
          <a href="/blog/" class="sound-interactive interactive-rainbow uppercase text-sm tracking-wider px-3 py-2 rounded-md cursor-pointer transition-colors hover:text-white">Blog</a>
        </div>
        <a href="mailto:hello@thomasgraves.art" class="sound-interactive hidden md:inline-block interactive-rainbow px-6 py-3 font-semibold uppercase tracking-wider rounded-lg">Contact</a>
      </nav>
    </header>
    <main>
      
      <div class="py-8">
        <section class="py-16">
  <div class="max-w-4xl mx-auto">
    <a href="/blog/" class="interactive-rainbow inline-block mb-8 px-3 py-2 rounded-md">&larr; Back</a>
    <div class="text-center mb-8">
      
      <p class="text-sm text-gray-500 mb-2">May 14, 2021</p>
      
      <h1 class="text-4xl tracking-tight uppercase font-bold text-white" style="letter-spacing: 0.1em;">Devlog: Trumpet Test in MR</h1>
    </div>
    
    <div class="aspect-w-16 aspect-h-9 rounded-lg overflow-hidden mb-12 shadow-lg bg-black">
      <iframe src="https://www.youtube.com/embed/jM_3Ma0daAA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="w-full h-full"></iframe>
    </div>
    
    <div class="prose prose-invert prose-lg max-w-none text-gray-300">
      <p>Check out our latest trumpet test in mixed reality! A little Haydn in color.</p>

    </div>
  </div>
</section>
      </div>
      
    </main>
    <footer id="page-footer" class="text-center py-12 mt-16 border-t border-[var(--color-border)]">
      <p class="text-gray-500">&copy; 2025 Thomas Graves. All Rights Reserved.</p>
    </footer>
  </div>

  <script>
    // AUDIO CONFIGURATION - Edit these settings to customize sounds
    const AUDIO_CONFIG = {
      masterVolume: -10,
      synths: {
        hover: { type: 'fatsine2', volume: -24, envelope: { attack: 0.1, decay: 0.2, sustain: 0.3, release: 0.8 } },
        click: { type: 'fatsine4', volume: -10, envelope: { attack: 0.01, decay: 0.1, sustain: 0, release: 0.3 } },
        highClick: { type: 'sine', volume: -14, envelope: { attack: 0.01, decay: 0.05, sustain: 0, release: 0.2 } },
        pad: { type: 'AMSynth', volume: -20, envelope: { attack: 2.0, decay: 1.0, sustain: 0.8, release: 4.0 } },
        melody: { type: 'triangle8', volume: -18, envelope: { attack: 0.1, decay: 0.2, sustain: 0.5, release: 1.0 } }
      },
      effects: { reverb: { roomSize: 3, wetness: 0.4 }, filter: { frequency: "2m" } }
    };

    // Musical Data from Original
    const NOTE_COLORS = {
      'C': 0xff2a2a, 'C#': 0xff8000, 'D': 0xffff00, 'D#': 0x40ff00,
      'E': 0x00ffff, 'F': 0x0080ff, 'F#': 0x8000ff, 'G': 0xff00ff,
      'G#': 0xff2a2a, 'A': 0xff8000, 'A#': 0xffff00, 'B': 0x40ff00
    };
    const CHROMATIC_SCALE = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
    const TONE_ROWS = [
      ['G4', 'F#4', 'A4', 'C#5', 'D#4', 'B4', 'C4', 'E4', 'F4', 'G#4', 'A#4', 'D4'],
      ['A4', 'G#4', 'B4', 'D#5', 'F#4', 'C#4', 'D4', 'F4', 'G4', 'A#4', 'C5', 'E4'],
      ['C4', 'D4', 'B3', 'E4', 'F#4', 'G#4', 'A#4', 'C#5', 'D#5', 'F5', 'G5', 'A5'],
      ['F#4', 'E4', 'G4', 'D#4', 'C#4', 'A#3', 'A3', 'C4', 'D4', 'F4', 'G#4', 'B4'],
      ['D4', 'E4', 'C#4', 'F#4', 'G#4', 'A#4', 'B4', 'D#5', 'F5', 'G5', 'A5', 'C5']
    ];
    const WHOLE_TONE_SCALES = [
      ['C', 'D', 'E', 'F#', 'G#', 'A#'],
      ['C#', 'D#', 'F', 'G', 'A', 'B']
    ];

    // App State
    const AppState = {
      isSoundEnabled: false,
      activePage: 'hero',
      currentToneRowIndex: 0,
      isTransitioning: false,
      pageToShowAfterTransition: null,
      transitionTimeoutId: null,
      visualQueue: [],
      wholeToneStartIndex: 0,
      wholeToneDirection: 1,
    };

    document.addEventListener('DOMContentLoaded', async () => {
      // Sound Engine Class
      class SoundEngine {
        constructor() {
          this.synths = {};
          this.effects = {};
          this.melodySequence = null;
          this.isSetup = false;
          this.isEnabled = false;
        }

        async setup() {
          if (this.isSetup) return;
          try {
            await Tone.start();
            
            this.effects.reverb = new Tone.Reverb(AUDIO_CONFIG.effects.reverb.roomSize).toDestination();
            this.effects.reverb.wet.value = AUDIO_CONFIG.effects.reverb.wetness;
            
            this.effects.filter = new Tone.AutoFilter(AUDIO_CONFIG.effects.filter.frequency)
              .connect(this.effects.reverb).start();
            
            this.synths.hover = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.hover.type },
              envelope: AUDIO_CONFIG.synths.hover.envelope,
              volume: AUDIO_CONFIG.synths.hover.volume
            }).connect(this.effects.reverb);
            
            this.synths.click = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.click.type },
              envelope: AUDIO_CONFIG.synths.click.envelope,
              volume: AUDIO_CONFIG.synths.click.volume
            }).connect(this.effects.reverb);
            
            this.synths.highClick = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.highClick.type },
              envelope: AUDIO_CONFIG.synths.highClick.envelope,
              volume: AUDIO_CONFIG.synths.highClick.volume
            }).connect(this.effects.reverb);
            
            this.synths.pad = new Tone.PolySynth(Tone.AMSynth, {
              envelope: AUDIO_CONFIG.synths.pad.envelope,
              volume: AUDIO_CONFIG.synths.pad.volume
            }).connect(this.effects.filter);
            
            this.synths.melody = new Tone.Synth({
              oscillator: { type: AUDIO_CONFIG.synths.melody.type },
              envelope: AUDIO_CONFIG.synths.melody.envelope,
              volume: AUDIO_CONFIG.synths.melody.volume
            }).connect(this.effects.filter);
            
            this.isSetup = true;
            console.log('🎵 Sound Engine initialized');
          } catch (error) {
            console.error('❌ Sound Engine setup failed:', error);
          }
        }

        enable() {
          if (!this.isSetup) { console.warn('Sound engine not setup yet'); return; }
          this.isEnabled = true;
          AppState.isSoundEnabled = true;
          Tone.Destination.mute = false;
          this.startSoundscape();
          document.body.classList.add('sound-is-on');
          console.log('🔊 Sound enabled');
        }

        disable() {
          this.isEnabled = false;
          AppState.isSoundEnabled = false;
          if (this.isSetup) { Tone.Destination.mute = true; this.stopSoundscape(); }
          document.body.classList.remove('sound-is-on');
          console.log('🔇 Sound disabled');
        }

        toggle() { if (this.isEnabled) { this.disable(); } else { this.enable(); } return this.isEnabled; }

        startSoundscape() {
          if (!this.isEnabled || !this.isSetup) return;
          const now = Tone.now();
          this.synths.pad.triggerAttackRelease(['A2', 'C3', 'E3', 'G3'], '4m', now);
          this.synths.pad.triggerAttack(['D2', 'F#2', 'A2', 'C3'], now + Tone.Time('4m').toSeconds());
          this.synths.hover.triggerAttack('D2');
          Tone.Transport.start();
          this.setMelodyForPage(AppState.activePage);
        }

        stopSoundscape() {
          if (!this.isSetup) return;
          this.synths.pad.releaseAll();
          this.synths.hover.volume.rampTo(-60, 0.1);
          if (this.melodySequence) {
            this.melodySequence.stop().dispose();
            this.melodySequence = null;
          }
          Tone.Transport.stop();
        }

        setMelodyForPage(pageId) {
          if (!AppState.isSoundEnabled || !this.isSetup) return;
          
          if (this.melodySequence) {
            this.melodySequence.stop().dispose();
            this.melodySequence = null;
          }
          
          let notes;
          if (pageId === 'work' || pageId === 'hero') {
            notes = TONE_ROWS[AppState.currentToneRowIndex];
          } else {
            const startNoteName = CHROMATIC_SCALE[AppState.wholeToneStartIndex];
            const scale = WHOLE_TONE_SCALES[0].includes(startNoteName) ? WHOLE_TONE_SCALES[0] : WHOLE_TONE_SCALES[1];
            const startIndexInScale = scale.indexOf(startNoteName);
            notes = [];
            for (let i = 0; i < 12; i++) {
              const step = i < 6 ? i : 10 - i;
              const noteIndex = (startIndexInScale + step + scale.length) % scale.length;
              const noteBase = scale[noteIndex];
              const octave = (i < 6 || i === 10) ? '5' : '4';
              notes.push(noteBase + octave);
            }
            AppState.wholeToneStartIndex += AppState.wholeToneDirection;
            if (AppState.wholeToneStartIndex >= 11) {
              AppState.wholeToneDirection = -1;
              AppState.wholeToneStartIndex = 11;
            } else if (AppState.wholeToneStartIndex <= 0) {
              AppState.wholeToneDirection = 1;
              AppState.wholeToneStartIndex = 0;
            }
          }
          
          this.melodySequence = new Tone.Sequence((time, note) => {
            this.synths.melody.triggerAttackRelease(note, "8n", time);
            Tone.Draw.schedule(() => {
              AppState.visualQueue.push(note);
            }, time);
          }, notes, '4n').start(0);
          this.melodySequence.loop = true;
        }

        playHoverSound() { if (this.synths.hover && this.isEnabled) this.synths.hover.volume.rampTo(-24, 0.5); }
        stopHoverSound() { if (this.synths.hover && this.isEnabled) this.synths.hover.volume.rampTo(-60, 0.8); }
        playClickSound() { if (this.isEnabled) { this.synths.click?.triggerAttackRelease('G3', '0.5'); this.synths.highClick?.triggerAttackRelease('G5', '0.5'); } }
      }

      // Initialize sound engine
      const soundEngine = new SoundEngine();
      await soundEngine.setup();

      // Blog post data - loaded from Eleventy
      const BlogData = {
        posts: [
          {
            title: "The Art of Improvisation",
            date: "December 31, 2024",
            url: "/posts/improvisation/",
            image: "images/pic04.jpg",
            videoId: "",
            tags: ["post","Music Theory","Creativity"],
            content: "<p>This webpage is under construction. Check back soon to learn more about jazz improvisation and our process of creativity.</p>\n"
          },{
            title: "Devlog: Trumpet Test in MR",
            date: "May 14, 2021",
            url: "/posts/devlog-2021-05-15/",
            image: "",
            videoId: "jM_3Ma0daAA",
            tags: ["post","Devlog","Portraits of Change"],
            content: "<p>Check out our latest trumpet test in mixed reality! A little Haydn in color.</p>\n"
          },{
            title: "Devlog: VFX MIDI Tests",
            date: "April 14, 2021",
            url: "/posts/devlog-2021-04-15/",
            image: "",
            videoId: "l-iUqews7Q0",
            tags: ["post","Devlog","Portraits of Change"],
            content: "<p>This video contains a collection of different effects I've made for Portraits. In this 2D Unity scene, I can test different MIDI driven VFX without needing VR. There isn't sound, but these effects are being driven by my MIDI keyboard in real-time.</p>\n"
          },{
            title: "Devlog: University Demo",
            date: "April 11, 2021",
            url: "/posts/devlog-2021-04-12/",
            image: "",
            videoId: "xYRqNQzCxVM",
            tags: ["post","Devlog","Update"],
            content: "<p>I got to bring my VR/AR rig down to my university to demonstrate a VR conducting app I have been working on for a class, and couldn't help myself in sharing some Portraits stuff as well! Here is a short demonstration of the Portraits of Change beta software and AR prototype with the man who taught me piano, Greg Creager! The past year has been very challenging on all of us... I shifted gears, and started working on an educational tool to help teach basic conducting... With the pandemic soon recessing as we ramp up vaccinations, the prospect of live performance with live audiences becomes possible again. There will be a Portraits performance as my senior recital by the end of the year.</p>\n"
          },{
            title: "Devlog: Coronavirus Update",
            date: "April 26, 2020",
            url: "/posts/devlog-2020-04-27/",
            image: "",
            videoId: "RUBBKnUVU-s",
            tags: ["post","Devlog","Update"],
            content: "<p>Well, that happened. Coronavirus has altered our way of life, and the performing arts have suffered. The prospects of live music performance are not looking great... I am still working through Portraits, hoping to attain some Vive trackers and adding more visual effects and refining the AR pass-through prototype. In our recent update, I added HDRP support and am using VFX graphs exclusively for the particle system.</p>\n"
          },{
            title: "Devlog: SteamVR Tracking",
            date: "March 26, 2020",
            url: "/posts/devlog-2020-03-27/",
            image: "",
            videoId: "C5lcmrWpCXE",
            tags: ["post","Devlog","Hardware"],
            content: "<p>We have upgraded to SteamVR tracking! With the addition of the Index headset to our mixed reality arsenal, we can start prototyping AR pass-through with the ZED mini and LEAP motion sensor in a well-tracked environment with multiple objects in scene.</p>\n"
          },{
            title: "Devlog: Multi-Instrument Harmony",
            date: "February 4, 2020",
            url: "/posts/devlog-2020-02-05/",
            image: "",
            videoId: "FFIsxg-flIg",
            tags: ["post","Devlog","Milestone"],
            content: "<p>I managed to get a recording with our session pianist Noah Suazo. It was a really great experience and really rich to finally see some multi instrument harmony in action. We are both energized to see what more of our music looks like! I also used footage from this session for my Peak Arts Prize 2020 proposal.</p>\n"
          },{
            title: "Devlog: Trumpet Module",
            date: "January 8, 2020",
            url: "/posts/devlog-2020-01-09/",
            image: "",
            videoId: "IxDf7hlPQLw",
            tags: ["post","Devlog","Milestone"],
            content: "<p>This is where things get good. A little over a full year has past and we have a fully functioning trumpet module working! 0.2.5 will also be our first multi-instrument supported version.</p>\n"
          },{
            title: "Devlog: Post-Festival Update",
            date: "September 14, 2019",
            url: "/posts/devlog-2019-09-15/",
            image: "",
            videoId: "VPJgtfEtFgQ",
            tags: ["post","Devlog","Event"],
            content: "<p>With the What If... Festival wrapped up, we are bunkering down to develop our MIDI conversion system after all this time researching and prototyping on piano. 0.2.4 will see the addition of the trumpet along with bug fixes and updates to the performance mode of Portraits of Change.</p>\n"
          },{
            title: "Devlog: AR MIDI Color Test",
            date: "August 24, 2019",
            url: "/posts/devlog-2019-08-25/",
            image: "",
            videoId: "Q6Wat4iVT-M",
            tags: ["post","Devlog","AR"],
            content: "<p>We have been hard at work testing our MIDI color system in augmented reality, while still polishing the VR experience for our upcoming events. We were fortunate to host our session pianist Noah Suazo for our most recent test, to uncover the possibilities of augmented reality! This test was used with the LIV software, and it is a really incredible tool for mixed reality recording.</p>\n"
          },{
            title: "Devlog: Fundraising & First Event",
            date: "July 10, 2019",
            url: "/posts/devlog-2019-07-11/",
            image: "",
            videoId: "NMaVNASWMLU",
            tags: ["post","Devlog","Update"],
            content: "<p>July Update- It has been a busy summer for Portraits of Change! We have officially reached our first fundraising milestone- to raise $1000! We also have our first event finalized! On September 14th, 2019, you can find a booth of Portraits of Change at the What If... Festival of Innovation &amp; Imagination in Downtown Colorado Springs!</p>\n"
          },{
            title: "Devlog: Initial Prototype",
            date: "April 14, 2019",
            url: "/posts/devlog-2019-04-15/",
            image: "",
            videoId: "3-ZnpXlRGYI",
            tags: ["post","Devlog","Prototype"],
            content: "<p>We had made some breakthroughs in developing an initial prototype of the idea of incorporating VR/AR into a live music performance. With help of some incredible developers and through the discovery of amazing open-sourced projects and samples, I was able to build a Frankenstein of a Unity project that actually works! MIDI turned out to be a key player in utilizing physical interfaces to generate low-latency effects directly from the music itself.</p>\n"
          },{
            title: "Why Jazz? A History of Innovation",
            date: "March 14, 2019",
            url: "/posts/why-jazz/",
            image: "images/pic04.jpg",
            videoId: "",
            tags: ["post","Music","History","Philosophy"],
            content: "<p>You may be wondering what all the fuss is about. Is it &quot;elevator music&quot;? Is it for pretentious cocktail parties? After learning its history, you decide.</p>\n<p>Jazz sits at the center of Portraits of Change. What evolved between a confrontation in culture led to a syncretism of art. As technology continues to develop in both the music world and in other fields, there arises a need to continue Jazz's cultural heritage in new, dynamic ways.</p>\n<p>Portraits of Change initially started as a recital focused on music innovation. I wanted to highlight past innovative works within jazz, and try to paint a &quot;portrait&quot; of the composer through their own music. A portrait can be defined as a painting, drawing, photo, or visual representation of a person usually depicting only the face or head and shoulders. A more abstract definition is a representation or impression of someone. That is exactly what we set out with our audiovisual environments, to paint with sound and light an impression of the mood and likeness of the composer.</p>\n<blockquote>\n<p>&quot;If a Jazz musician plays someone else's song, he has a responsibility to make a distinct &amp; original statement.&quot;</p>\n</blockquote>\n<p>I hope that by adding a visual component to the music, it makes it more accessible to untrained ears and more enjoyable and immersive for everyone. I hope to spark joy and interest in these wonderful musicians throughout time that have inspired me and to foster more listeners to their music through this medium of mixed reality and music.</p>\n"
          },
        ]
      };

      // Simple Page Manager - just handles sound and basic interactions
      const PageManager = {
        init() {
          AppState.currentToneRowIndex = Math.floor(Math.random() * TONE_ROWS.length);
          AppState.activePage = 'hero';
          
          // Set melody based on current page
          const path = window.location.pathname;
          if (path.includes('/work')) {
            AppState.activePage = 'work';
          } else if (path.includes('/about')) {
            AppState.activePage = 'about';  
          } else if (path.includes('/blog')) {
            AppState.activePage = 'blog';
          }
          
          soundEngine.setMelodyForPage(AppState.activePage);
          
          // Load blog content if on blog page
          if (AppState.activePage === 'blog') {
            this.loadBlogContent();
          }
        },

        loadBlogContent() {
          const blogGrid = document.getElementById('blog-grid');
          if (!blogGrid) return;

          blogGrid.innerHTML = BlogData.posts.map(post => {
            let imageUrl = 'images/pic01.jpg';
            if (post.videoId && post.videoId !== '') {
              imageUrl = `https://img.youtube.com/vi/${post.videoId}/maxresdefault.jpg`;
            } else if (post.image && post.image !== '') {
              imageUrl = post.image;
            }

            return `
              <article class="bg-[var(--color-bg-card)] rounded-xl overflow-hidden hover:shadow-lg transition-shadow duration-300 group">
                <div class="relative">
                  <img src="${imageUrl}" alt="${post.title}" class="w-full h-48 object-cover group-hover:scale-105 transition-transform duration-300">
                  ${post.videoId && post.videoId !== '' ? `
                    <div class="absolute inset-0 flex items-center justify-center">
                      <div class="bg-red-600 rounded-full p-3 shadow-lg">
                        <svg class="w-8 h-8 text-white ml-1" fill="currentColor" viewBox="0 0 20 20">
                          <path d="M6.3 2.841A1.5 1.5 0 004 4.11V15.89a1.5 1.5 0 002.3 1.269l9.344-5.89a1.5 1.5 0 000-2.538L6.3 2.841z"/>
                        </svg>
                      </div>
                    </div>
                  ` : ''}
                </div>
                <div class="p-6">
                  <div class="flex flex-wrap gap-2 mb-3">
                    ${post.tags.filter(tag => tag !== 'post').map(tag => `<span class="inline-block bg-[var(--color-secondary)] text-xs font-medium px-2.5 py-1 rounded-full">${tag}</span>`).join('')}
                  </div>
                  <h3 class="text-xl font-bold text-white mb-2 group-hover:text-gray-300 transition-colors">${post.title}</h3>
                  <p class="text-gray-500 text-sm mb-4">${post.date}</p>
                  <a href="${post.url}" class="inline-block sound-interactive interactive-rainbow px-4 py-2 font-semibold text-sm uppercase tracking-wider rounded-lg transition-colors">Read More</a>
                </div>
              </article>
            `;
          }).join('');
        }
      };
      
      // Get DOM elements
      const soundToggleBtn = document.getElementById('sound-toggle');
      const soundOnIcon = document.getElementById('sound-on-icon');
      const soundOffIcon = document.getElementById('sound-off-icon');
      const canvas = document.getElementById('bg-canvas');
      
      // 3D Background System (simplified)
      const ThreeDBackground = {
        scene: null, camera: null, renderer: null, worldGrid: new Map(),
        cameraTargetPosition: new THREE.Vector3(0, 0, 2),
        mouse: { x: 0, y: 0 },
        baseSphereColor: new THREE.Color(0x222222),
        sphereGeometry: null, sphereMaterial: null,
        CHUNK_SIZE: 12, VIEW_DISTANCE: 3,

        init() {
          console.log('🌟 Initializing ThreeDBackground...');
          this.scene = new THREE.Scene();
          this.camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
          this.renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true });
          this.renderer.setSize(window.innerWidth, window.innerHeight);
          this.scene.fog = new THREE.Fog(0x0A0A0A, 20, 80);
          this.sphereGeometry = new THREE.SphereGeometry(0.15, 16, 16);
          this.sphereMaterial = new THREE.MeshBasicMaterial({ color: this.baseSphereColor });
          this.camera.position.z = 2;
          this.cameraTargetPosition.copy(this.camera.position);
          this.updateWorldGrid(true);
          console.log('✅ ThreeDBackground initialized, starting animation...');
          this.animate();
          window.addEventListener('resize', () => this.onWindowResize());
          document.addEventListener('mousemove', (e) => this.onMouseMove(e));
        },

        onWindowResize() {
          this.camera.aspect = window.innerWidth / window.innerHeight;
          this.camera.updateProjectionMatrix();
          this.renderer.setSize(window.innerWidth, window.innerHeight);
        },

        onMouseMove(event) {
          this.mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
        },

        generateChunk(chunkX, chunkY, chunkZ) {
          const key = `${chunkX},${chunkY},${chunkZ}`;
          if (this.worldGrid.has(key)) return;
          const chunkSpheres = [];
          const offset = { x: chunkX * this.CHUNK_SIZE, y: chunkY * this.CHUNK_SIZE, z: chunkZ * this.CHUNK_SIZE };
          const octave = (chunkX % 8 + 8) % 8 + 2;
          for (let i = 0; i < 3; i++) {
            const sphere = new THREE.Mesh(this.sphereGeometry, this.sphereMaterial.clone());
            const noteIndex = Math.floor(Math.random() * 12);
            sphere.position.set(
              offset.x + (Math.random() - 0.5) * this.CHUNK_SIZE,
              offset.y + (Math.random() - 0.5) * this.CHUNK_SIZE,
              offset.z + (Math.random() - 0.5) * this.CHUNK_SIZE
            );
            sphere.userData = {
              noteName: CHROMATIC_SCALE[noteIndex] + octave,
              noteBase: CHROMATIC_SCALE[noteIndex],
              activePulses: [],
            };
            this.scene.add(sphere);
            chunkSpheres.push(sphere);
          }
          this.worldGrid.set(key, chunkSpheres);
        },

        removeChunk(key) {
          if (!this.worldGrid.has(key)) return;
          this.worldGrid.get(key).forEach(sphere => {
            this.scene.remove(sphere);
            sphere.material.dispose();
          });
          this.worldGrid.delete(key);
        },

        triggerVisualPulse(noteName) {
          const noteBase = noteName.replace(/\d/g, '');
          const color = new THREE.Color(NOTE_COLORS[noteBase] || 0xffffff);
          this.worldGrid.forEach(chunk => {
            chunk.forEach(sphere => {
              if (sphere.userData.noteBase === noteBase) {
                this.lightUpSphereWave(sphere, color, 0);
              }
            });
          });
        },

        lightUpSphereWave(sphere, color, generation) {
          if (generation > 2) return;
          sphere.userData.activePulses.push({
            color,
            startTime: Date.now(),
            intensity: 0.6 - (generation * 0.2)
          });
          const allVisibleSpheres = Array.from(this.worldGrid.values()).flat();
          const neighbors = allVisibleSpheres.map(other => ({
            sphere: other,
            dist: sphere.position.distanceTo(other.position)
          })).filter(item => item.sphere !== sphere && item.dist < this.CHUNK_SIZE / 2)
            .sort((a, b) => a.dist - b.dist)
            .slice(0, 4)
            .map(item => item.sphere);
          
          setTimeout(() => {
            neighbors.forEach(neighbor => this.lightUpSphereWave(neighbor, color, generation + 1));
          }, 150);
        },

        updateWorldGrid(isInitialLoad = false) {
          const camChunk = {
            x: Math.round(this.camera.position.x / this.CHUNK_SIZE),
            y: Math.round(this.camera.position.y / this.CHUNK_SIZE),
            z: Math.round(this.camera.position.z / this.CHUNK_SIZE),
          };
          for (let x = camChunk.x - this.VIEW_DISTANCE; x <= camChunk.x + this.VIEW_DISTANCE; x++) {
            for (let y = camChunk.y - this.VIEW_DISTANCE; y <= camChunk.y + this.VIEW_DISTANCE; y++) {
              for (let z = camChunk.z - this.VIEW_DISTANCE; z <= camChunk.z + this.VIEW_DISTANCE; z++) {
                this.generateChunk(x, y, z);
              }
            }
          }
        },

        animate() {
          requestAnimationFrame(() => this.animate());
          
          // Process visual queue from melody system
          while (AppState.visualQueue.length > 0) {
            const note = AppState.visualQueue.shift();
            this.triggerVisualPulse(note);
          }
          
          this.updateWorldGrid();
          
          // Update sphere colors based on active pulses
          const now = Date.now();
          const allSpheres = Array.from(this.worldGrid.values()).flat();
          allSpheres.forEach(sphere => {
            let finalColor = this.baseSphereColor.clone();
            
            if (sphere.userData.activePulses.length > 0) {
              sphere.userData.activePulses = sphere.userData.activePulses.filter(pulse => {
                const age = now - pulse.startTime;
                const maxAge = 1500;
                if (age < maxAge) {
                  const intensity = (1.0 - (age / maxAge)) * pulse.intensity;
                  finalColor.add(pulse.color.clone().multiplyScalar(intensity));
                  return true;
                }
                return false;
              });
            }
            
            sphere.material.color.lerp(finalColor, 0.2);
          });
          
          const parallaxInput = this.mouse.x;
          const parallaxStrength = 0.25;
          const targetX = this.cameraTargetPosition.x + (parallaxInput * parallaxStrength);
          this.camera.position.lerp(new THREE.Vector3(targetX, this.cameraTargetPosition.y, this.cameraTargetPosition.z), 0.05);
          this.renderer.render(this.scene, this.camera);
        }
      };

      // Setup event listeners
      soundToggleBtn.addEventListener('click', async () => {
        const isEnabled = soundEngine.toggle();
        soundOnIcon.classList.toggle('hidden', !isEnabled);
        soundOffIcon.classList.toggle('hidden', isEnabled);
      });

      // Sound interaction events
      document.body.addEventListener('mouseover', e => {
        if (e.target.closest('.sound-interactive')) {
          soundEngine.playHoverSound();
        }
      });

      document.body.addEventListener('mouseout', e => {
        if (e.target.closest('.sound-interactive')) {
          soundEngine.stopHoverSound();
        }
      });

      document.body.addEventListener('click', e => {
        if (e.target.closest('.sound-interactive')) {
          soundEngine.playClickSound();
        }
      });

      // Reality Engine Button
      const realityEngineBtn = document.getElementById('reality-engine-btn');
      if (realityEngineBtn) {
        realityEngineBtn.addEventListener('click', async (e) => {
          e.preventDefault();
          
          // Enable audio context
          if (!AppState.isSoundEnabled) {
            await soundEngine.enable();
            AppState.isSoundEnabled = true;
            document.getElementById('sound-off-icon').classList.add('hidden');
            document.getElementById('sound-on-icon').classList.remove('hidden');
          }
          
          // Play click sound
          soundEngine.playClickSound();
          
          // Trigger visual pulse
          if (ThreeDBackground && ThreeDBackground.scene) {
            const randomNote = CHROMATIC_SCALE[Math.floor(Math.random() * CHROMATIC_SCALE.length)];
            AppState.visualQueue.push(randomNote + '4');
          }
          
          // Optional: Navigate to work section after a brief delay
          setTimeout(() => {
            PageManager.showPage('work');
          }, 500);
        });
      }

      // Initialize
      ThreeDBackground.init();
      PageManager.init();
    });
  </script>
</body>
</html>